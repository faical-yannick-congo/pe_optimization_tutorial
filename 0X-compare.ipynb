{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peformance Comprison\n",
    "\n",
    "So, now that we've explored a number of optimization schemes, how do they compare? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading some notebook wide features. Memory profiler and snakeviz are tools we will use to debug our codes. Bokeh and Holoviews are plotting libraries. The debugger was used in the development of this notebook. Hopefully we won't need it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler\n",
    "%load_ext snakeviz\n",
    "%load_ext cython\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh','matplotlib')\n",
    "from IPython.core import debugger\n",
    "ist = debugger.set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to gather all of our profiling data.\n",
    "\n",
    "**Disclaimer** I am quite new to pandas and still learning its idioms so my usage below may not be ideal. Please let me know (verbally or via PR) if you have a cleaner way to gather these data into a DataFrame. Thanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pstats\n",
    "\n",
    "\n",
    "energies = []\n",
    "names = []\n",
    "files = [f for f in os.listdir('./energy/') if f[0] != '.']\n",
    "for file in files:\n",
    "    names.append(os.path.splitext(os.path.basename(file))[0])\n",
    "    with open('./energy/' + file,'r') as f:\n",
    "        energies.append(float(f.readline()))\n",
    "es = pd.Series(energies,index=names,name='Energy')   \n",
    "\n",
    "\n",
    "times = []\n",
    "time_names = []\n",
    "mem_names = []\n",
    "mems = []\n",
    "files = [f for f in os.listdir('./prof/') if f[0] != '.']\n",
    "for file in files:\n",
    "    fname = './prof/' + file\n",
    "    name,ext = os.path.splitext(os.path.basename(file))\n",
    "    if ext == '.prof':\n",
    "        time_names.append(name)\n",
    "        times.append(pstats.Stats(fname).total_tt)\n",
    "    elif ext == '.memprof':\n",
    "        mem_names.append(name)\n",
    "        with open(fname,'r') as f:\n",
    "            mems.append([float(i) for i in f.readlines()])\n",
    "ts = pd.Series(times,index=time_names,name='RunTime') \n",
    "ms1 = pd.Series([i[0] for i in mems],index=mem_names,name='MaxMem')   \n",
    "ms2 = pd.Series([i[1] for i in mems],index=mem_names,name='IncMem')   \n",
    "\n",
    "df = pd.concat([es,ts,ms1,ms2],axis=1).sort_values(by='RunTime')\n",
    "\n",
    "#Add in relative runtime column\n",
    "df.insert(2,column='RelTime',value=df['RunTime']/df['RunTime'][df.index=='python'][0])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can throw the DataFrame at HoloViews and get a nice, formatted bar chart back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Bars [xrotation=40,height=400,width=600,show_grid=True,tools=['hover']]\n",
    "%%opts Bars [fontsize={'ticks':14,'labels':16}] (alpha=0.6)\n",
    "\n",
    "hvb1 = (hv.Bars(df.reset_index(),kdims=['index'],vdims=['RelTime'])\n",
    "         .redim.label(RelTime = 'Relative Time',index='Approach'))\n",
    "\n",
    "hvb2 = (hv.Bars(df.reset_index(),kdims=['index'],vdims=['RunTime'])\n",
    "        .redim.label(RunTime = 'Run Time',index='Approach')\n",
    "        .redim.unit(RunTime = 's'))\n",
    "\n",
    "hvb3 = (hv.Bars(df.reset_index(),kdims=['index'],vdims=['MaxMem'])\n",
    "        .redim.label(MaxMem = 'Maximum Memory',index='Approach')\n",
    "        .redim.unit(MaxMem = 'MB'))\n",
    "\n",
    "(hvb1 + hvb2 + hvb3).cols(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaways\n",
    "\n",
    "- Pure *Python* is very memory efficient, but poor in terms of execution.\n",
    "- Even a naive *Numpy* implementation is ~10x faster than pure *Python*\n",
    "- Numpy also offers both improvements in code readability and simplicity\n",
    "- Unfortunately, our Numba implementations were always worse than the functions they wrapped\n",
    "- Cython is the clear winner, but involves increased effort.\n",
    "- Top speed is always achieved with proper tuning and profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
